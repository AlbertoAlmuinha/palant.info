{
  "publishDate": "2009-03-06 20:13:38",
  "author": "SZ",
  "authorUrl": "",
  "id": "000387"
}

	<p>I quite agree.</p>

	<p>Also if you are saying that <span class="caps">XSS</span> protection is in4evitabley going to fail then you might as well scrap the whole thing.  But then you would have NO protection in that category, which is the reason it was implemented in the first place!</p>

	<p>From what I have read sofar, it seems you are wanting to say that whitelisting is not what should be used.  But, instead blacklisting is what should be used.</p>

	<p>If this is the case, I have several weaknesses I can see.  First, Blacklisting inevitably will make a mistake and not list a vendor, thus enabling an attack.  The Attacker could also feasibly enable an address that is not blacklisted.  <span class="caps">PLUS</span>, the list would have to be huge if it was to provide adequate protection, thus slowing the browser down, and increasing its memory usage.</p>

	<p>Have a good day. :p</p>

